# Meteorological Data Analysis System
This project is a Python data pipeline that consumes meteorological information, processes it, generates insights using a large language model (LLM), and saves the results in structured formats.

### Project Description
The system performs the following steps:
1. Extraction: Consumes real-time weather data from the OpenWeatherMap API for a predefined list of Brazilian cities.
2. Transformation: Processes the raw data using the Pandas library, converting temperatures from Kelvin to Celsius and categorizing weather conditions.
3. LLM Analysis: Uses the OpenAI API to generate a textual and structured analysis of general weather conditions and recommendations, based on the transformed data.
4. Persistence: Saves the processed data to a CSV file and the LLM's analysis to a JSON file.


### Execution Instructions
##### prerequisites:
- Python 3.8+
- Git

1. Clone the Repository to your local machine:<br>
   git clone https://github.com/anaClara404/meteorological_data_analysis.git<br>
   cd meteorological_data_analysis
2. Create and activate a virtual environment:<br>
    python -m venv virtual_env #create the virtual env<br>
    virtual_env\Scripts\activate #activate the virtual environment (Windows)<br>
    source virtual_env/bin/activate #activate the virtual environment (macOS/Linux)
3. Set Up Environment Variables
   - Create a file named .env in the root of the project and add your API keys, ex:
   - #OpenWeatherMap API Key<br>
     OPENWEATHER_API_KEY="your_key_here"
     
     #OpenAI API Key (for the language model)<br>
     OPENAI_API_KEY="your_key_here"

     #Specify the LLM model to be used<br>
     LLM_MODEL="gpt-4o-mini"

4. Run the project:
   - python main.py
  
*IMPORTANT: the .gitignore file is already configured to prevent the .env file from being uploades to Github.
  

### Example Output
=== INÍCIO DO PIPELINE DE ANÁLISE METEOROLÓGICA === <br>
[1] Extraindo dados da API OpenWeather...<br>
[2] Transformando dados com pandas...<br>
[3] Salvando dados estruturados...<br>
[OK] CSV salvo em data/outputs\weather_summary_20250921T192912Z.csv<br>
[4] Gerando análise com modelo gpt-4.1-mini...<br>
[5] Salvando análise do LLM...<br>
[OK] JSON salvo em data/outputs\analysis_20250921T192918Z.json<br>
=== PIPELINE CONCLUÍDO COM SUCESSO ===

At the end, two types of files will be generated in the data/outputs folder:
- CSV: A table with structured data for the cities.
- JSON: A file containing the full analysis generated by the LLM + metadata.


### Technical Decisions
- Virtual Environment: Using venv to isolate project dependencies and maintain a clean environment.
- Environment Variables: Using .env with python-dotenv to securely manage API keys, following the principle of separating configuration from code.
- Modular Code Structure: The code is split into modules (extract.py, transform.py, persist.py, llm.py, main.py) to improve organization, readability, and maintainability.
- Error Handling: The pipeline includes try-except blocks with retries to handle network failures and API errors (like timeouts), increasing the system's robustness.


### Possible Future Improvements
- Asynchronous Processing: Implement asynchronous requests (using libraries like aiohttp) to fetch data for all cities in parallel, reducing the pipeline's execution time.
- Graphical Interface: Create a simple interface (via command-line or web) to allow the user to dynamically input the list of cities.
- Orchestration: Use tools like Apache Airflow or Prefect to automate and schedule the pipeline's execution daily.
